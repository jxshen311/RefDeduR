---
title: "RefDeduR: a text-normalization and decision-tree aided R package enabling accurate and high-throughput reference deduplication for large datasets"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{RefDeduR: a text-normalization and decision-tree aided R package enabling accurate and high-throughput reference deduplication for large datasets}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(RefDeduR)
library(dplyr)
library(zeallot)  # to use `%<-%`

knitr::opts_chunk$set(eval = FALSE)  # temporary command; to disable the code chunks from running
```

## Introduction


#//TODO: to re-edit
{
We recommend treating these as modules. we suggest following the order, but you can stop anytime if you are satisfied with the number of records retained.

with the finely tuned text cleaning and normalization, even just exact match out competes many tools - alphabetic order is also very fast
}

## Example dataset

We use an example dataset to demonstrate the recommended pipeline of RefDeduR. The dataset contains all bibliographic records (n = 6384) retrieved in a systematic review on indoor surface microbiome studies. The systematic search was conducted on 2022-01-10 through 3 platforms (i.e., PubMed, Web of Science, and Scopus).

#//TODO: add info (1. preprocessing; 2. `bib_example_complete`)

## Pre-process

## Read bibliographic files into a data frame

We use function `revtools::read_bibliography()` to read bibTex file into a data frame.

-   I recommend using bibTex files here. According to past experience, reading .ris file seems to have formatting errors.
-   Alternative function: `synthesisr::read_refs()`

```{r}
# Output the path to the example dataset
path_to_bibfile <- system.file("extdata", "dataset_trans_unaccented.bib", package = "RefDeduR")

# Print the path to confirm
print(path_to_bibfile)

# Read bibTex file into a data frame
b <- revtools::read_bibliography(path_to_bibfile) # 6384 rows

# We can check the number of missing values in each column.
# Pay attention to `title` column as we expect all records to have titles.
# If your dataset has only a few NAs in title, maybe it is worth resolving the missing values manually. If your dataset has a substantial number of NAs in title (according to our experience, this is extremely rare), consider sub-setting the dataset and deduplicating separately.
colSums(is.na(b))
```

## Text cleaning and normalization

Before deduplication, we first apply multiple fine text cleaning and normalization to the dataset. A finer text normalization increases the chance of successful deduplication at the exact match step, where both accuracy and confidence are assured.

This step includes not only standard text normalization such as converting letters to lowercase, but also tailored operations in response to patterns we observed, such as removing trademark "(TM)" in `title`, removing English stop words in `journal`, and removing publisher/citation information in `abstract`. Additionally, we extract helper columns which we will use downstream. See details in each `norm_` and `extract_` functions' documentation pages.

```{r}
b <- norm_df(b)
# This function `norm_df` wraps all (1) text normalization and (2) helper field extraction that are needed.
# By default, expect the function to add 8 more columns compared with the original data frame.
# Alternatively, if you want to customize the normalization operations, refer to its sub-functions by `?norm_df` or hack the source code.
```

## Deduplicate by exact match

We suggest first deduplicating by exact match based on 1) "doi_norm", 2) "title", and 3) "title_norm" in order. DOI is decisive (i.e., unique to a publication). Title is also highly selective.

Note that here we assume different research papers wouldn't have 100% identical titles before text normalization. This assumption should hold in most normal cases as indicated previously [(1)](https://cran.r-project.org/web/packages/synthesisr/vignettes/synthesisr_vignette.html) [(2)](https://www.researchgate.net/post/Is-it-possible-to-publish-an-article-with-nearly-similar-title-of-a-previously-published-one).

The assumption may not apply to special publication types in studies that heavily focus on clinical therapies. For example, we observed that identical titles present in the deduplicated dataset in [this paper](https://systematicreviewsjournal.biomedcentral.com/articles/10.1186/s13643-021-01583-y#Sec2).

### First, we deduplicate based on "doi_norm" and "title".

```{r}
# We remove the identified duplicates without manual review because this is fairly conservative.
b1 <- dedu_exact(b, match_by = c("doi_norm", "title"))
# The most recent version will be retained at removal.
```

### Then, we deduplicate based on "title_norm"

To make sure that we don't delete unique records, we introduce a `double_check` mechanism here and output the duplicate sets with different `check_by` (defaults to `"first_author_last_name"`) to `b1_manual_check` for manual review.

Usually, the number of duplicate sets requires review is very small (e.g., in this case, only 1 set needs to be reviewed).

It is worth noting that incorporating the `double_check` mechanism here is extremely conservative. If double checking is not needed, you can incorporate `"title_norm"` into `dedu_exact()`.

```{r}
c(b1, b1_manual_check) %<-% dup_find_exact(b1, match_by = "title_norm", double_check = TRUE, check_by = "first_author_last_name_norm")  # Syntax %<-% must be used in this case to have the function return 2 data frames.
```

If `b1_manual_check` is empty, nothing needs to be manually reviewed. Otherwise, you can either (1) review it in a data frame format (e.g., preview in R or `write.xlsx()`) or (2) call revtools shiny app to review.

-   **Note:** It seems that `revtools::screen_duplicates()` can only display duplicate **pairs** correctly (i.e., it only displays 2 records of a duplicate set with more than 2 records). *So I recommend trying option (1) first.*

-   Command to call revtools shiny app: `revtools::screen_duplicates(as.data.frame(b1_manual_check))`

If the records reviewed are duplicates, we can proceed to removing duplicates. Otherwise, if you find a record unique, we can mark them by modifying their `match` number.

-   Using `match == 3011` and `first_author_last_name_norm == "de Oliveira"` as an example, run `b1$match[which(b1$match == 3011 & b1$first_author_last_name_norm == "de Oliveira")] <- max(b1$match)+1`

-   Alternatively, we can use function `synthesisr::override_duplicates()`: `b1$match <- synthesisr::override_duplicates(b1$match, 3011)`. Note that this only works for duplicate pairs. If the duplicate set has more than 2 records, this can only mark the final record unique.

Once we finalize `match`, we can remove duplicates.

```{r}
# In this example, no unique record is found in b1_manual_check.
b2 <- b1[!duplicated(b1$match), ]
# The most recent version will be retained at removal.

# In order not to interfere downstream processes, we remove the "match" column
b2 <- select(b2, -match)
```

> üóíÔ∏è Although it is not included in this standard pipeline, you can try further performing exact match based on "abstract_norm".

## Deduplicate by fuzzy match

After we remove all duplicates by the high-confidence exact match, we now proceed to fuzzy match. Fuzzy match is made by calculating string similarity based on Levenshtein edit distance.

Two major practical challenges of making the fuzzy-match deduplication process both accurate and high-throughput are

1.  How do we choose a sensible cutoff threshold for the similarity score?

2.  How do we accelerate the "manual review" step and reduce burden of manual screening?

We propose two strategies to address these challenges correspondingly.

1.  We examine the similarity distribution plots and use the inflection point of the curve as the sensible cutoff threshold. This is a dataset-aware method, and it also allows fine-tuning of the cutoff threshold.

2.  We introduce a decision tree that incorporates multiple fields to automate the "manual review" step. This is especially helpful for large datasets, in which case the number of duplicate sets requiring manual review could be unfeasibly high (e.g., revtools output \~1,400 duplicate sets for manual confirmation when treating this example dataset).

To improve the computational efficiency, we divide this process into 2 steps: (1) order the records alphabetically according to `title_norm` and compare only between the adjacent rows; (2) perform pairwise comparisons between records within the same group partitioned by the first 2 letters of `first_author_last_name_norm`.

### Step 1: order + adjacent

Firstly, we calculate string similarity between adjacent rows for columns `"title_norm"` and `"abstract_norm"`.

```{r}
c(b2, b2_simi) %<-% simi_order_adj(b2, order_by = "title_norm")
# Computing time estimation: ~ 47 sec for this data frame (3837 rows) on a Macbook Pro (Apple M1 Pro chip basic model, memory: 16 GB).
```

Then we plot similarity distributions of normalized title and abstract to choose cutoffs.

```{r}
# Distribution of similarity scores based on normalized title
p_b2_ti <- plot_simi_dist(b2_simi, "title_simi")
p_b2_ti  # show plot in the Plots tab

# Distribution of similarity scores based on normalized abstract
p_b2_ab <- plot_simi_dist(b2_simi, "abstract_simi")
p_b2_ab  # show plot in the Plots tab
```

According to the plots, 0.7 or 0.6 seems sensible cutoff threshold. For demonstration purpose, we use 0.6 here. We use `dup_find_fuzzy_adj()` to find potential duplicates by fuzzy match of string similarity between adjacent rows. The function outputs two data frames: (1) `b2` with `"match"` column added; (2) A data frame listing `id` of duplicate pairs.

```{r}
c(b2, id_dup_pair_adj) %<-% dup_find_fuzzy_adj(b2, b2_simi, cutoff_title = 0.6, cutoff_abstract = 0.6)
```

Per the 2nd strategy, we introduce the decision tree to semi-automate the "manual review" step. Decisions are added to the `"decision"` column in `id_dup_pair`. There could be 3 levels of decisions, "duplicate", "not duplicate", and "check". If the decision is "not duplicate", `"match"` column in `df` will be modified. To ensure a high accuracy, especially a low false positive rate, output "check" is kept in the decision tree.

```{r}
c(b2, id_dup_pair_adj) %<-% decision_tree_adj(b2, id_dup_pair_adj)
```

Once we get the algorithm-generated decisions, we can deduplicate accordingly for different scenarios.

```{r}
# For the "duplicate", we can just deduplicate by `dup_rm_adj()`. 
b2_inter <- dup_rm_adj(b2, id_dup_pair_adj)

# For the "check", we call revtools shiny app to review the duplicate pairs.
# In the app, we select "Yes" for "Is there a variable describing duplicates in this dataset?" and "match" for "Select column containing duplicate data".
# At this step, we finish removing duplicates or keeping record pairs in the app. We click "Not duplicates" if the pair is not duplicated. Or we click "Select Entry #1" or "Select Entry #2" to keep one of the two.
# After reviewing all potential duplicates, don't forget to click "Save Data" and "Exit App" to return the results to the R workspace. In this case, the results will be returned to variable `b3`.
# See revtools tutorial for more instructions: https://revtools.net/deduplication.html
b3 <- revtools::screen_duplicates(b2_inter)  


# remove helper columns
b3 <- select(b3, -c(id, match, matches))
```

### Step 2: partition + pairwise

We further look for potential duplicates according to pairwise string similarity between all records within the same partitioned group for columns `"title_norm"` and `"abstract_norm"`.

By default, we partition the dataset by the first 2 letters of `first_author_last_name_norm`. This is more efficient than another popular partitioning parameter - year - for datasets that are skewed towards recent years. Additionally, with the prevalence of preprints, partitioning by `"year"` becomes less accurate. Nevertheless, you can customize the partitioning parameter by preference.

Following a pipeline similar to that in step 1, we first calculate string similarity. Because we partition the dataset, results are now stored in lists (as compared to data frames in step 1).

```{r}
c(ls_b3, ls_b3_simi) %<-% simi_ptn_pair(b3, partition_by = "first_two_letters_first_author_last_name")
# Computing time estimation: ~ 23 min for this data frame (3832 rows) on a Macbook Pro (Apple M1 Pro chip basic model, memory: 16 GB). You can consider running it on a high performance computing cluster if shortening the running time is of high priority.
```

Then we find potential duplicates.

```{r}
id_dup_pair_pairwise <- dup_find_fuzzy_pairwise(ls_b3, ls_b3_simi, cutoff_title = 0.6, cutoff_abstract = 0.6)
```

> üóíÔ∏è Cutoff thresholds in `dup_find_fuzzy_adj()` are usually applicable here. Alternatively, you can re-examine the similarity distribution plots by `plot_simi_dist()` and choose sensible values. Example commands are shown below.
>
> ```{r}
> # Merge similarity list into a data frame
> b3_plot <- do.call("rbind", ls_b3_simi)
> rownames(b3_plot) <- NULL
> b3_plot <- tibble::rownames_to_column(b3_plot, var = "id")
> >
> # Plot: Distribution of similarity scores based on normalized title
> p_b3_ti <- plot_simi_dist(b3_plot, "title_simi")
> p_b3_ti  # show plot in the Plots tab
> >
> # Plot: Distribution of similarity scores based on normalized abstract
> p_b3_ab <- plot_simi_dist(b3_plot, "abstract_simi")
> p_b3_ab  # show plot in the Plots tab
> ```

We apply the decision tree to potential duplicates.

```{r}
id_dup_pair_pairwise <- decision_tree_pairwise(ls_b3, id_dup_pair_pairwise)
```

For the duplicate pairs with a "check" decision, we output them into a data frame for manual review.

```{r}
df_check_pairwise <- dup_screen_pairwise(ls_b3, id_dup_pair_pairwise)
```

Similarly, we can either (1) review them directly in a data frame format (e.g., preview in R or write.xlsx()) or (2) call revtools shiny app for visulization, by `revtools::screen_duplicates(df_check_pairwise)`. However, we don't resolve duplicates directly in the revtools shiny app. Instead, we use `dup_resolve_pairwise()` to change decisions from "check" to "duplicate" or "not duplicate" according to manual review results.

```{r}
# All 4 duplicate pairs in this example dataset are "not duplicate".
id_dup_pair_pairwise <- dup_resolve_pairwise(
  id_dup_pair_pairwise,
  df_check_pairwise,
  match_index = c(1, 2, 3, 4),
  result = "not duplicate")
```

Afterwards, we remove duplicates by `dup_rm_pairwise()`. 

```{r}
b4 <- dup_rm_pairwise(ls_b3, id_dup_pair_pairwise, to_dataframe = TRUE)

# remove helper columns
b4 <- select(b4, -id, -partition)
```

# Export the deduplicated dataset to .bib or .ris formats

```{r}
revtools::write_bibliography(b4, "inst/extdata/dataset_deduplicated.ris", format = "ris")  # export .ris
# or export .bib
#// revtools::write_bibliography(b4, "inst/extdata/dataset_deduplicated.bib", format = "bib")  

# Alternative function: synthesisr::write_refs()
```


