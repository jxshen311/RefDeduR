<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="RefDeduR">
<title>RefDeduR: a text-normalization and decision-tree aided R package enabling accurate and high-throughput reference deduplication for large datasets • RefDeduR</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="RefDeduR: a text-normalization and decision-tree aided R package enabling accurate and high-throughput reference deduplication for large datasets">
<meta property="og:description" content="RefDeduR">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">RefDeduR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item">
  <a class="nav-link" href="../articles/RefDeduR.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>RefDeduR: a text-normalization and decision-tree aided R package enabling accurate and high-throughput reference deduplication for large datasets</h1>
                        <h4 data-toc-skip class="author">Jiaxian Shen,
Fangqiong Ling, Erica M. Hartmann</h4>
            
      
      
      <div class="d-none name"><code>RefDeduR.Rmd</code></div>
    </div>

    
    
<p><strong>✏️</strong> If you use RefDeduR, please cite: &lt;//TODO: the
paper&gt;</p>
<p>❓ If you run into issues with the package, please open an issue at
<a href="https://github.com/jxshen311/RefDeduR" class="external-link uri">https://github.com/jxshen311/RefDeduR</a> or email
<u>jiaxianshen2022@u.northwestern.edu</u>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">RefDeduR</span><span class="op">)</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/nteetor/zeallot" class="external-link">zeallot</a></span><span class="op">)</span>  <span class="co"># to use `%&lt;-%`</span></span></code></pre></div>
<div class="section level3">
<h3 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h3>
<p>As the scientific literature grows exponentially and research becomes
increasingly interdisciplinary, accurate and high-throughput reference
deduplication is vital in evidence synthesis studies (e.g., systematic
reviews, meta-analyses) to ensure the completeness of datasets while
reduce the manual screening burden. To address these emerging needs, we
developed RefDeduR. We modularize the deduplication pipeline into
finely-tuned text normalization, three-step exact matching, and two-step
fuzzy matching processes. The package features a decision-tree algorithm
and considers preprints and conference proceedings when they co-exist
with a peer-reviewed version.</p>
<p>Below, we demonstrate the functionality of RefDeduR with an example
pipeline.</p>
</div>
<div class="section level3">
<h3 id="example-dataset">Example dataset<a class="anchor" aria-label="anchor" href="#example-dataset"></a>
</h3>
<p>We use an example dataset to demonstrate the recommended pipeline of
RefDeduR. The dataset contains all bibliographic records (n = 6384)
retrieved in a systematic review on indoor surface microbiome studies.
The systematic search was conducted on 2022-01-10 through 3 platforms
(i.e., PubMed, Web of Science, and Scopus).</p>
</div>
<div class="section level3">
<h3 id="pre-processing-transliterate-non-ascii-characters">Pre-processing: transliterate non-ASCII characters<a class="anchor" aria-label="anchor" href="#pre-processing-transliterate-non-ascii-characters"></a>
</h3>
<p>The transliteration process includes 2 parts: (1) transliterate
common Greek letters to their names (e.g., α to alpha, β to beta) and
(2) transliterate accented characters to ASCII characters (e.g., á to a,
ä to a).</p>
<p><strong>Rationale:</strong> This increases the chance of successful
deduplication by exact matching. This also reduces noises when
partitioning the dataset by the first 2 letters of
<code>first_author_last_name_norm</code> at the fuzzy matching step. For
example, a record titled “Carriage and population genetics of extended
spectrum <strong>β</strong>-lactamase-producing Escherichia coli in cats
and dogs in New Zealand” sometimes has the title “Carriage and
population genetics of extended spectrum
<strong>beta</strong>-lactamase-producing Escherichia coli in cats and
dogs in New Zealand”. Author names “Álvarez-Fraga, L. and Pérez, A.” are
sometimes “Alvarez-Fraga, L. and Perez, A.”.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Get the path to the example dataset</span></span>
<span><span class="va">input_file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.file.html" class="external-link">system.file</a></span><span class="op">(</span><span class="st">"extdata"</span>, <span class="st">"dataset_raw.bib"</span>, package <span class="op">=</span> <span class="st">"RefDeduR"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Specify the path to the output file. Here we put it in the same directory but you can modify the path to wherever you want to store the output file.</span></span>
<span><span class="va">transliterated_file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.file.html" class="external-link">system.file</a></span><span class="op">(</span><span class="st">"extdata"</span>, <span class="st">"dataset_transliterated.bib"</span>, package <span class="op">=</span> <span class="st">"RefDeduR"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="../reference/norm_transliteration.html">norm_transliteration</a></span><span class="op">(</span><span class="va">input_file</span>, <span class="va">transliterated_file</span>, method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"greek_letter-name"</span>, <span class="st">"any-ascii"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<blockquote>
<p>⚒️ <strong><em>Alternatively</em></strong>, python scripts developed
on the basis of <code>unidecode</code> package are provided. The scripts
are ready to be run in terminal. Performance of the R function and the
python scripts are generally similar, with only little difference
induced by the difference of R package <code>stringi</code> and python
package <code>unidecode</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transliterate common Greek letters to their names</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> transliteration_greek_to_name.py <span class="op">&lt;</span>path/to/input_file<span class="op">&gt;</span> <span class="op">&lt;</span>path/to/output_file<span class="op">&gt;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Transliterate accented characters to ASCII characters </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> transliteration_unaccent.py <span class="op">&lt;</span>path/to/input_file<span class="op">&gt;</span> <span class="op">&lt;</span>path/to/output_file<span class="op">&gt;</span></span></code></pre></div>
</blockquote>
</div>
<div class="section level3">
<h3 id="read-the-bibliographic-file-into-a-data-frame">Read the bibliographic file into a data frame<a class="anchor" aria-label="anchor" href="#read-the-bibliographic-file-into-a-data-frame"></a>
</h3>
<p>We use function <code><a href="https://rdrr.io/pkg/revtools/man/read_bibliograpy.html" class="external-link">revtools::read_bibliography()</a></code> to read
the transliterated bibTex file into a data frame.</p>
<ul>
<li><p>We recommend using bibTex files here. According to past
experience, reading .ris file seems to result in formatting
errors.</p></li>
<li><p>Alternative function:
<code><a href="https://rdrr.io/pkg/synthesisr/man/read_refs.html" class="external-link">synthesisr::read_refs()</a></code></p></li>
<li><div>
<p>🗒️ <u><em>Comparison of the two import functions:</em></u></p>
<p><code><a href="https://rdrr.io/pkg/synthesisr/man/read_refs.html" class="external-link">synthesisr::read_refs()</a></code> seems better at parsing special
characters. “β-α-β” can be retained, while the text becomes “Î²-Î±-Î²”
when using <code><a href="https://rdrr.io/pkg/revtools/man/read_bibliograpy.html" class="external-link">revtools::read_bibliography()</a></code>. However, a
potential benefit of <code><a href="https://rdrr.io/pkg/revtools/man/read_bibliograpy.html" class="external-link">revtools::read_bibliography()</a></code> is that
it keeps the citation key (e.g., “RN13774” in the first row of record
“<span class="citation">@article</span>{RN13774,”) in a column named
“label”. If the .bib file is exported from Endnote (the case of this
example dataset), this citation key can serve as a unique identifier.
This information is also preserved in Covidence export. Covidence is an
online systematic review management platform, which is a typical
downstream step following reference deduplication. If preserving the
citation key (or a unique identifier) across processes is desired,
consider switching to <code><a href="https://rdrr.io/pkg/revtools/man/read_bibliograpy.html" class="external-link">revtools::read_bibliography()</a></code> or
importing twice with both functions and combine the data frames.</p>
</div></li>
</ul>
<p>Here we use <code><a href="https://rdrr.io/pkg/revtools/man/read_bibliograpy.html" class="external-link">revtools::read_bibliography()</a></code> because we
have transliterated the Greek letters and we want the unique
identifier.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Read the transliterated bibTex file into a data frame</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu">revtools</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/revtools/man/read_bibliograpy.html" class="external-link">read_bibliography</a></span><span class="op">(</span><span class="va">transliterated_file</span><span class="op">)</span>  <span class="co"># 6384 rows</span></span>
<span></span>
<span><span class="co"># We can check the number of missing values in each column.</span></span>
<span><span class="co"># Pay attention to `title` column as we expect all records to have titles.</span></span>
<span><span class="co"># If your dataset has only a few NAs in title, maybe it is worth resolving the missing values manually. If your dataset has a substantial number of NAs in title (according to our experience, this is extremely rare), consider sub-setting the dataset and deduplicating separately.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">colSums</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">b</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="text-cleaning-and-normalization">Text cleaning and normalization<a class="anchor" aria-label="anchor" href="#text-cleaning-and-normalization"></a>
</h3>
<p>Before deduplication, we first apply multiple finely-tuned text
cleaning and normalization to the dataset. A finer text normalization
increases the chance of successful deduplication at the exact matching
step, where both accuracy and confidence are assured.</p>
<p>This step includes not only standard text normalization such as
converting letters to lowercase, but also tailored operations in
response to patterns we observed, such as removing trademark “(TM)” in
<code>title</code>, removing English stop words in <code>journal</code>,
and removing publisher/citation information in <code>abstract</code>.
Additionally, we extract helper columns which we will use downstream.
See details in each <code>norm_</code> and <code>extract_</code>
functions’ documentation pages.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/norm_df.html">norm_df</a></span><span class="op">(</span><span class="va">b</span><span class="op">)</span></span>
<span><span class="co"># This function `norm_df` wraps all (1) text normalization and (2) helper field extraction that are needed.</span></span>
<span><span class="co"># By default, expect the function to add 8 more columns compared with the original data frame.</span></span>
<span><span class="co"># Alternatively, if you want to customize the normalization operations, refer to its sub-functions by `?norm_df` or hack the source code.</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="deduplicate-by-exact-matching">Deduplicate by exact matching<a class="anchor" aria-label="anchor" href="#deduplicate-by-exact-matching"></a>
</h3>
<p>We suggest first deduplicating by exact matching based on 1)
“doi_norm”, 2) “title”, and 3) “title_norm” in order. DOI is decisive
(i.e., unique to a publication). Title is also highly selective.</p>
<p>Note that here we assume different research papers wouldn’t have 100%
identical titles before text normalization. This assumption should hold
in most normal cases as indicated previously <a href="https://cran.r-project.org/web/packages/synthesisr/vignettes/synthesisr_vignette.html" class="external-link">(1)</a>
<a href="https://www.researchgate.net/post/Is-it-possible-to-publish-an-article-with-nearly-similar-title-of-a-previously-published-one" class="external-link">(2)</a>.</p>
<p>The assumption may not apply to special publication types in studies
that heavily focus on clinical therapies. For example, we observed that
identical titles present in the deduplicated dataset in <a href="https://systematicreviewsjournal.biomedcentral.com/articles/10.1186/s13643-021-01583-y#Sec2" class="external-link">this
paper</a>.</p>
<div class="section level4">
<h4 id="first-we-deduplicate-based-on-doi_norm-and-title-">First, we deduplicate based on “doi_norm” and “title”.<a class="anchor" aria-label="anchor" href="#first-we-deduplicate-based-on-doi_norm-and-title-"></a>
</h4>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># We remove the identified duplicates without manual review because this is fairly conservative.</span></span>
<span><span class="va">b1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dedu_exact.html">dedu_exact</a></span><span class="op">(</span><span class="va">b</span>, match_by <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"doi_norm"</span>, <span class="st">"title"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># The most recent version will be retained at removal.</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="then-we-deduplicate-based-on-title_norm">Then, we deduplicate based on “title_norm”<a class="anchor" aria-label="anchor" href="#then-we-deduplicate-based-on-title_norm"></a>
</h4>
<p>To make sure that we don’t delete unique records, we introduce a
<code>double_check</code> mechanism here and output the duplicate sets
with different <code>check_by</code> (defaults to
<code>"first_author_last_name"</code>) to <code>b1_manual_check</code>
for manual review.</p>
<p>Usually, the number of duplicate sets requires review is very small
(e.g., in this case, only 1 set needs to be reviewed).</p>
<p>It is worth noting that incorporating the <code>double_check</code>
mechanism here is extremely conservative. If double checking is not
needed, you can incorporate <code>"title_norm"</code> into
<code><a href="../reference/dedu_exact.html">dedu_exact()</a></code>.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">b1</span>, <span class="va">b1_manual_check</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html" class="external-link">%&lt;-%</a></span> <span class="fu"><a href="../reference/dup_find_exact.html">dup_find_exact</a></span><span class="op">(</span><span class="va">b1</span>, match_by <span class="op">=</span> <span class="st">"title_norm"</span>, double_check <span class="op">=</span> <span class="cn">TRUE</span>, check_by <span class="op">=</span> <span class="st">"first_author_last_name_norm"</span><span class="op">)</span>  <span class="co"># Syntax %&lt;-% must be used in this case to have the function return 2 data frames.</span></span></code></pre></div>
<p>If <code>b1_manual_check</code> is empty, nothing needs to be
manually reviewed. Otherwise, you can either (1) review it in a data
frame format (e.g., preview in R or <code>write.xlsx()</code>) or (2)
call revtools shiny app to review.</p>
<ul>
<li><p><strong>Note:</strong> It seems that
<code><a href="https://rdrr.io/pkg/revtools/man/screen_duplicates.html" class="external-link">revtools::screen_duplicates()</a></code> can only display duplicate
<strong>pairs</strong> correctly (i.e., it only displays 2 records of a
duplicate set with more than 2 records). <em>So we recommend trying
option (1) first.</em></p></li>
<li><p>Command to call revtools shiny app:
<code>revtools::screen_duplicates(as.data.frame(b1_manual_check))</code></p></li>
</ul>
<p>If the records reviewed are duplicates, we can proceed to removing
duplicates. Otherwise, if you find a record unique, we can mark them by
modifying their <code>match</code> number.</p>
<ul>
<li><p>Using <code>match == 3011</code> and
<code>first_author_last_name_norm == "de Oliveira"</code> as an example,
run
<code>b1$match[which(b1$match == 3011 &amp; b1$first_author_last_name_norm == "de Oliveira")] &lt;- max(b1$match)+1</code></p></li>
<li><p>Alternatively, we can use function
<code><a href="https://rdrr.io/pkg/synthesisr/man/override_duplicates.html" class="external-link">synthesisr::override_duplicates()</a></code>:
<code>b1$match &lt;- synthesisr::override_duplicates(b1$match, 3011)</code>.
Note that this only works for duplicate pairs. If the duplicate set has
more than 2 records, this can only mark the final record
unique.</p></li>
</ul>
<p>Once we finalize <code>match</code>, we can remove duplicates.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># In this example, no unique record is found in b1_manual_check.</span></span>
<span><span class="va">b2</span> <span class="op">&lt;-</span> <span class="va">b1</span><span class="op">[</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/duplicated.html" class="external-link">duplicated</a></span><span class="op">(</span><span class="va">b1</span><span class="op">$</span><span class="va">match</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="co"># The most recent version will be retained at removal.</span></span>
<span></span>
<span><span class="co"># In order not to interfere downstream processes, we remove the "match" column</span></span>
<span><span class="va">b2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">b2</span>, <span class="op">-</span><span class="va">match</span><span class="op">)</span></span></code></pre></div>
<blockquote>
<p>🗒️ Although it is not included in this standard pipeline, you can try
further performing exact matching based on “abstract_norm”.</p>
</blockquote>
</div>
</div>
<div class="section level3">
<h3 id="deduplicate-by-fuzzy-matching">Deduplicate by fuzzy matching<a class="anchor" aria-label="anchor" href="#deduplicate-by-fuzzy-matching"></a>
</h3>
<p>After we remove all duplicates by the high-confidence exact matching,
we now proceed to fuzzy matching. Fuzzy matching is made by calculating
string similarity based on Levenshtein edit distance.</p>
<p>Two major practical challenges of making the fuzzy-matching
deduplication process both accurate and high-throughput are</p>
<ol style="list-style-type: decimal">
<li><p>How do we choose a sensible cutoff threshold for the similarity
score?</p></li>
<li><p>How do we accelerate the “manual review” step and reduce burden
of manual screening?</p></li>
</ol>
<p>We propose two strategies to address these challenges
correspondingly.</p>
<ol style="list-style-type: decimal">
<li><p>We examine the similarity distribution plots and use the
inflection point of the curve as the sensible cutoff threshold. This is
a dataset-aware method, and it allows fine-tuning of the cutoff
threshold.</p></li>
<li><p>We introduce a decision tree that incorporates multiple fields to
semi-automate the “manual review” step. This is especially helpful for
large datasets, in which case the number of duplicate sets requiring
manual review could be unfeasibly high (e.g., revtools output ~1,400
duplicate sets for manual confirmation when treating this example
dataset).</p></li>
</ol>
<p>To improve the computational efficiency, we divide this process into
2 steps: (1) order the records alphabetically according to
<code>title_norm</code> and compare only between the adjacent rows; (2)
perform pairwise comparisons between records within the same group
partitioned by the first 2 letters of
<code>first_author_last_name_norm</code>.</p>
<div class="section level4">
<h4 id="part-1-order-adjacent">Part 1: order + adjacent<a class="anchor" aria-label="anchor" href="#part-1-order-adjacent"></a>
</h4>
<p>Firstly, we calculate string similarity between adjacent rows for
columns <code>"title_norm"</code> and <code>"abstract_norm"</code>.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">b2</span>, <span class="va">b2_simi</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html" class="external-link">%&lt;-%</a></span> <span class="fu"><a href="../reference/simi_order_adj.html">simi_order_adj</a></span><span class="op">(</span><span class="va">b2</span>, order_by <span class="op">=</span> <span class="st">"title_norm"</span><span class="op">)</span></span>
<span><span class="co"># Computing time estimation: ~ 47 sec for this data frame (3837 rows) on a Macbook Pro (Apple M1 Pro chip basic model, memory: 16 GB).</span></span></code></pre></div>
<p>Then we plot similarity distributions of normalized title and
abstract to choose cutoffs.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Distribution of similarity scores based on normalized title</span></span>
<span><span class="va">p_b2_ti</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plot_simi_dist.html">plot_simi_dist</a></span><span class="op">(</span><span class="va">b2_simi</span>, <span class="st">"title_simi"</span><span class="op">)</span></span>
<span><span class="va">p_b2_ti</span>  <span class="co"># show plot in the Plots tab</span></span>
<span></span>
<span><span class="co"># Distribution of similarity scores based on normalized abstract</span></span>
<span><span class="va">p_b2_ab</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plot_simi_dist.html">plot_simi_dist</a></span><span class="op">(</span><span class="va">b2_simi</span>, <span class="st">"abstract_simi"</span><span class="op">)</span></span>
<span><span class="va">p_b2_ab</span>  <span class="co"># show plot in the Plots tab</span></span></code></pre></div>
<p><embed src="title_norm.pdf" style="width:100.0%;height:5in"></embed><embed src="abstract_norm.pdf" style="width:100.0%;height:5in"></embed></p>
<p>The plots suggest a cutoff score of 0.7 or 0.6 for the title and 0.3
for the abstract. For demonstration purpose, we use 0.7 and 0.3 here.
The selected cutoffs are then passed to
<code><a href="../reference/dup_find_fuzzy_adj.html">dup_find_fuzzy_adj()</a></code> to locate potential duplicates. The
function outputs 2 data frames: (1) the input data frame <code>b2</code>
with <code>"match"</code> column added and (2) a data frame listing
<code>id</code> of duplicate pairs (<code>id_dup_pair_adj</code>).</p>
<blockquote>
<p>🗒️ Note that the inflection point serves more like a number to begin
with. The result should usually be satisfactory, but you may tweak the
values to see if the performance can be further improved.</p>
</blockquote>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">b2</span>, <span class="va">id_dup_pair_adj</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html" class="external-link">%&lt;-%</a></span> <span class="fu"><a href="../reference/dup_find_fuzzy_adj.html">dup_find_fuzzy_adj</a></span><span class="op">(</span><span class="va">b2</span>, <span class="va">b2_simi</span>, cutoff_title <span class="op">=</span> <span class="fl">0.7</span>, cutoff_abstract <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span></span></code></pre></div>
<p>Per the 2nd strategy, we introduce the decision tree to semi-automate
the “manual review” step. Decisions are added to the
<code>"decision"</code> column in <code>id_dup_pair</code>. There could
be 3 levels of decisions, “duplicate”, “not duplicate”, and “check”. If
the decision is “not duplicate”, <code>"match"</code> column in
<code>df</code> will be modified. To ensure a high accuracy, especially
a low false positive rate, output “check” is kept in the decision
tree.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">b2</span>, <span class="va">id_dup_pair_adj</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html" class="external-link">%&lt;-%</a></span> <span class="fu"><a href="../reference/decision_tree_adj.html">decision_tree_adj</a></span><span class="op">(</span><span class="va">b2</span>, <span class="va">id_dup_pair_adj</span><span class="op">)</span></span></code></pre></div>
<p>Once we get the algorithm-generated decisions, we can deduplicate
accordingly for different scenarios.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># For the "duplicate", we can just deduplicate by `dup_rm_adj()`. </span></span>
<span><span class="va">b2_inter</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dup_rm_adj.html">dup_rm_adj</a></span><span class="op">(</span><span class="va">b2</span>, <span class="va">id_dup_pair_adj</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># For the "check", we call revtools shiny app to review the duplicate pairs.</span></span>
<span><span class="co"># In the app, we select "Yes" for "Is there a variable describing duplicates in this dataset?" and "match" for "Select column containing duplicate data".</span></span>
<span><span class="co"># At this step, we finish removing duplicates or keeping record pairs in the app. We click "Not duplicates" if the pair is not duplicated. Or we click "Select Entry #1" or "Select Entry #2" to keep one of the two.</span></span>
<span><span class="co"># After reviewing all potential duplicates, don't forget to click "Save Data" and "Exit App" to return the results to the R workspace. In this case, the results will be returned to variable `b3`.</span></span>
<span><span class="co"># See revtools tutorial for more instructions: https://revtools.net/deduplication.html</span></span>
<span><span class="va">b3</span> <span class="op">&lt;-</span> <span class="fu">revtools</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/revtools/man/screen_duplicates.html" class="external-link">screen_duplicates</a></span><span class="op">(</span><span class="va">b2_inter</span><span class="op">)</span>  </span>
<span></span>
<span></span>
<span><span class="co"># remove helper columns</span></span>
<span><span class="va">b3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">b3</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">id</span>, <span class="va">match</span>, <span class="va">matches</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="part-2-partition-pairwise">Part 2: partition + pairwise<a class="anchor" aria-label="anchor" href="#part-2-partition-pairwise"></a>
</h4>
<p>We further look for potential duplicates according to pairwise string
similarity between all records within the same partitioned group for
columns <code>"title_norm"</code> and <code>"abstract_norm"</code>.</p>
<p>By default, we partition the dataset by the first 2 letters of
<code>first_author_last_name_norm</code>. This is more efficient than
another popular partitioning parameter - year - for datasets that are
skewed towards recent years. Additionally, with the prevalence of
preprints, partitioning by <code>"year"</code> becomes less accurate.
Nevertheless, you can customize the partitioning parameter by
preference.</p>
<p>Following a pipeline similar to that in part 1, we first calculate
string similarity. Because we partition the dataset, results are now
stored in lists (as compared to data frames in part 1).</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">ls_b3</span>, <span class="va">ls_b3_simi</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html" class="external-link">%&lt;-%</a></span> <span class="fu"><a href="../reference/simi_ptn_pair.html">simi_ptn_pair</a></span><span class="op">(</span><span class="va">b3</span>, partition_by <span class="op">=</span> <span class="st">"first_two_letters_first_author_last_name"</span><span class="op">)</span></span>
<span><span class="co"># Computing time estimation: ~ 23 min for this data frame (3832 rows) on a Macbook Pro (Apple M1 Pro chip basic model, memory: 16 GB). You can consider running it on a high performance computing cluster if shortening the running time is of high priority.</span></span></code></pre></div>
<p>Then we flag potential duplicates.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">id_dup_pair_pairwise</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dup_find_fuzzy_pairwise.html">dup_find_fuzzy_pairwise</a></span><span class="op">(</span><span class="va">ls_b3</span>, <span class="va">ls_b3_simi</span>, cutoff_title <span class="op">=</span> <span class="fl">0.7</span>, cutoff_abstract <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span></span></code></pre></div>
<blockquote>
<p>🗒️ The cutoff thresholds can be inherited from part 1. To avoid
over-deleting unique records, we suggest tightening the cutoff of
abstract similarity to 0.7 (or 0.6) in this step, as opposed to 0.3 in
part 1, where the risk is mitigated by the more restricted ordering (in
contrast to the exhaustive pairwise comparison).</p>
</blockquote>
<p>We then apply the decision tree to potential duplicates.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">id_dup_pair_pairwise</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/decision_tree_pairwise.html">decision_tree_pairwise</a></span><span class="op">(</span><span class="va">ls_b3</span>, <span class="va">id_dup_pair_pairwise</span><span class="op">)</span></span></code></pre></div>
<p>For the duplicate pairs with a “check” decision, we output them into
a data frame for manual review.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df_check_pairwise</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dup_screen_pairwise.html">dup_screen_pairwise</a></span><span class="op">(</span><span class="va">ls_b3</span>, <span class="va">id_dup_pair_pairwise</span><span class="op">)</span></span></code></pre></div>
<p>Similarly, we can either (1) review them directly in a data frame
format (e.g., preview in R or write.xlsx()) or (2) call revtools shiny
app for visulization by
<code>revtools::screen_duplicates(df_check_pairwise)</code>. However, we
don’t resolve duplicates directly in the revtools shiny app. Instead, we
use <code><a href="../reference/dup_resolve_pairwise.html">dup_resolve_pairwise()</a></code> to change decisions from “check”
to “duplicate” or “not duplicate” according to the manual review
results.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># All 4 duplicate pairs in this example dataset are "not duplicate".</span></span>
<span><span class="va">id_dup_pair_pairwise</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dup_resolve_pairwise.html">dup_resolve_pairwise</a></span><span class="op">(</span></span>
<span>  <span class="va">id_dup_pair_pairwise</span>,</span>
<span>  <span class="va">df_check_pairwise</span>,</span>
<span>  match_index <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span>,</span>
<span>  result <span class="op">=</span> <span class="st">"not duplicate"</span><span class="op">)</span></span></code></pre></div>
<p>Afterwards, we remove duplicates by
<code><a href="../reference/dup_rm_pairwise.html">dup_rm_pairwise()</a></code>.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">b4</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dup_rm_pairwise.html">dup_rm_pairwise</a></span><span class="op">(</span><span class="va">ls_b3</span>, <span class="va">id_dup_pair_pairwise</span>, to_dataframe <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># remove helper columns</span></span>
<span><span class="va">b4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">b4</span>, <span class="op">-</span><span class="va">id</span>, <span class="op">-</span><span class="va">partition</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="export-the-deduplicated-dataset-to--bib-or--ris-formats">Export the deduplicated dataset to .bib or .ris formats<a class="anchor" aria-label="anchor" href="#export-the-deduplicated-dataset-to--bib-or--ris-formats"></a>
</h2>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">revtools</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/revtools/man/write_bibliography.html" class="external-link">write_bibliography</a></span><span class="op">(</span><span class="va">b4</span>, <span class="st">"inst/extdata/dataset_deduplicated.ris"</span>, format <span class="op">=</span> <span class="st">"ris"</span><span class="op">)</span>  <span class="co"># export .ris</span></span>
<span><span class="co"># or export .bib</span></span>
<span><span class="co">#// revtools::write_bibliography(b4, "inst/extdata/dataset_deduplicated.bib", format = "bib")  </span></span></code></pre></div>
<p>Alternative function: <code><a href="https://rdrr.io/pkg/synthesisr/man/write_refs.html" class="external-link">synthesisr::write_refs()</a></code>.
According to our observation,
<code><a href="https://rdrr.io/pkg/revtools/man/write_bibliography.html" class="external-link">revtools::write_bibliography()</a></code> seems to preserve more
fields in the exported file, but it’s always a good idea to test both
functions on your own dataset.</p>
<blockquote>
<p>🗒️ We export .ris file here because the downstream applications
(e.g., we tested Covidence , Rayyan, and Endnote) in our pipeline seem
easier to recognize a .ris file than a .bib file.</p>
</blockquote>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Jiaxian Shen.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
